{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign3_117CS0259.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4hK6MvRt_7c",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3: Face Recognition using PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK7PfcFPujHm",
        "colab_type": "text"
      },
      "source": [
        "##1. Dataset Upload and Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMjBPnhouq04",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Dataset Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6l2uSBqCHnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dataset\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMUYeTCbuwAH",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Dataset Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffxVwNxtZ1SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip att_faces_ORG.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiBQ_2vQu33f",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Verify the Dataset\n",
        "Verify if our datasets are correclty imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbeb9uDMCUxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f019dc8-a18a-44cf-f30f-61bff8c35fe7"
      },
      "source": [
        "# to chack the datasets are correctly uploaded and labeled.\n",
        "import os\n",
        "print(os.listdir(os.getcwd()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', '.ipynb_checkpoints', 'att_faces', 'att_faces_ORG.zip', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubs1jTN2vFUO",
        "colab_type": "text"
      },
      "source": [
        "## 2. Import of All Required Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8olN8QKCbU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OubSKnMHvMtS",
        "colab_type": "text"
      },
      "source": [
        "##3. Steps For Training Dataseet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNvBf72vvWLR",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Generating Face Dataset\n",
        "Each face image is represented in the form a matrix having m rows and n columns,\n",
        "where each pixel (x,y) such that xm, and yn shows pixel location of the image as\n",
        "well as the direction.\n",
        "For the simplicity we are assuming each face image as a column vector, if we have p\n",
        "images then the size of the face database will be mn*p.<br>\n",
        "Let’s say face database is denoted as $(Face Db)_{mn*p}$*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOrHSXTCcs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "164ddd48-ca11-472e-e242-1cfd281611e0"
      },
      "source": [
        "Face_db = np.zeros(shape=(400, 112*92)) # image input in p*mn format\n",
        "y = np.zeros(shape=(400, 1), dtype=np.int8) # name of the corresponding image\n",
        "p = 0; # increment operator to store each data\n",
        "for i in range(40):\n",
        "  images = os.listdir('./att_faces/s'+str(i+1)) # retrive every folder of my path\n",
        "  for image in images:\n",
        "    img = cv2.imread('./att_faces/s'+str(i+1)+\"/\"+image, cv2.IMREAD_GRAYSCALE) # read the input image\n",
        "    img = np.array(img, dtype=np.float64)\n",
        "    Face_db[p, :] = img.flatten() # flat the image as mentioned in document\n",
        "    y[p] = i+1 # label for the input data image\n",
        "    p += 1 \n",
        "print(Face_db)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 60.  60.  62. ...  32.  34.  34.]\n",
            " [ 63.  53.  35. ...  41.  10.  24.]\n",
            " [ 42.  41.  44. ...  42.  43.  41.]\n",
            " ...\n",
            " [123. 121. 126. ...  40.  35.  42.]\n",
            " [125. 124. 124. ...  36.  35.  34.]\n",
            " [125. 119. 124. ...  36.  39.  40.]]\n",
            "[[ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 1]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 8]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [ 9]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [10]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [11]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [12]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [13]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [14]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [15]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [16]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [17]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [18]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [19]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [20]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [21]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [22]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [23]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [24]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [25]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [26]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [27]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [28]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [29]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [30]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [31]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [32]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [33]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [34]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [35]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [36]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [37]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [38]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [39]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]\n",
            " [40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EexFXWDAyGuI",
        "colab_type": "text"
      },
      "source": [
        "###3.2 Perform Split of Data for Training and Testing Purpose\n",
        "split the 80% of data for training and remaining for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N23KOBYHq7ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2df0d0c8-6e54-42b4-a2ed-cfcff5c519dc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Face_db, y, train_size=0.8, random_state=0) # spliting by 80%\n",
        "print(X_train.shape)\n",
        "y_train.shape;\n",
        "X_test.shape;\n",
        "y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 10304)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wmMnsEfsYLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9a4ee96-01a9-43ba-ce8c-a1985921ffe8"
      },
      "source": [
        "X_train = X_train.T # to convert data to required format i.e mn*p\n",
        "X_test = X_test.T\n",
        "X_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10304, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1brg4DAyy5c",
        "colab_type": "text"
      },
      "source": [
        "###3.3 Calculate Mean\n",
        "Calculate the mean of each observation<br>\n",
        "Here mean vector will have the dimension of $(M)_{mn*1}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKDia8XXzC_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bda65d4c-83ff-4e4f-9b22-2bd1d0460c45"
      },
      "source": [
        "mean = np.mean(X_train, axis=1)\n",
        "mean = mean.reshape(mean.shape[0], 1) # convert pre ccalculated shape of (mn,) to (mn,1)\n",
        "print(mean.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5cuLwdEz2Y-",
        "colab_type": "text"
      },
      "source": [
        "###3.4 Calculate Deviation Matrix\n",
        "Subtract mean face from each face image, let’s say this mean zero face data as dev."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4axT27EEz6et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "2fd8a35f-9928-4bc1-95e1-685edd35992f"
      },
      "source": [
        "dev = X_train-mean\n",
        "print(dev)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-64.425    -38.425     56.575    ...   8.575     41.575     32.575   ]\n",
            " [-67.39375  -34.39375   57.60625  ...  14.60625   41.60625   31.60625 ]\n",
            " [-62.653125 -38.653125  55.346875 ...  12.346875  41.346875  32.346875]\n",
            " ...\n",
            " [ 72.3      -12.7        1.3      ... -37.7        9.3        5.3     ]\n",
            " [ 81.50625  -15.49375    2.50625  ... -34.49375    6.50625    6.50625 ]\n",
            " [ 89.93125  -13.06875    3.93125  ... -23.06875    9.93125    5.93125 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjtf_trY0IdN",
        "colab_type": "text"
      },
      "source": [
        "###3.5 Calculate Co-Variance of the Mean aligned faces \n",
        "Hence here will get covariance matrix of p * p dimension, which is easy to compute and process, the\n",
        "idea behind computing the surrogate covariance suggested by turk and peterland that,\n",
        "these are only the valid direction where we will get maximum variances, and rest of the\n",
        "directions are insignificant to us. Menas these are direction where we will get the\n",
        "eigenvalues and for rest we will get eigenvalues equal to zero.<br>So, take two column matrix and do vector dot prodect to get a scalar and store that in cov matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf586AVP6A6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d9f370a-5cf1-414d-ab78-9b63c8ea782b"
      },
      "source": [
        "# cov = np.zeros(shape=(320, 320))\n",
        "# for i in range(320):\n",
        "#   for j in range(320):\n",
        "#     cov[i, j] = np.dot(dev[:, i], dev[:, j])\n",
        "# print(cov)\n",
        "cov = np.dot(dev.T, dev) # calculating covariance matrix by above method\n",
        "                        # without using any explicit for loops\n",
        "                        # shape=p*p\n",
        "print(cov.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320, 320)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozON_8uX1C3Q",
        "colab_type": "text"
      },
      "source": [
        "###3.6 Eigenvalue and Eigenvector Decomposition\n",
        "Determine eigenvalue and eigenvector and  select the best direction from p directions, for this sort the eigenvalues in the\n",
        "descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXIM4HDU36P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a757a84a-c0df-434c-fc6b-1e8e55e42300"
      },
      "source": [
        "lambd, V = np.linalg.eig(cov) # lambd is eigenValue and V is eigenVector\n",
        "idx = np.argsort(lambd)[::-1] # get the indices in descending order according to data\n",
        "lambd = lambd[idx] # sort the value\n",
        "V = V[:, idx] # sort the vector\n",
        "V"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01619146, -0.14205076, -0.04834456, ..., -0.02417078,\n",
              "         0.00096708, -0.0559017 ],\n",
              "       [ 0.01466334,  0.05644305,  0.07213997, ...,  0.01059905,\n",
              "        -0.00629615, -0.0559017 ],\n",
              "       [ 0.02594551,  0.08169512, -0.07573807, ..., -0.01891108,\n",
              "         0.0264327 , -0.0559017 ],\n",
              "       ...,\n",
              "       [-0.06892213,  0.04050185,  0.00732537, ..., -0.01231234,\n",
              "        -0.01010536, -0.0559017 ],\n",
              "       [-0.06000398,  0.05717431, -0.06674366, ...,  0.02157954,\n",
              "         0.05177282, -0.0559017 ],\n",
              "       [-0.07397747,  0.06151273, -0.02102284, ...,  0.01594937,\n",
              "        -0.01071738, -0.0559017 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvYk8cr11cl4",
        "colab_type": "text"
      },
      "source": [
        "###3.7 Selection of Prominent Features\n",
        "decide a k value, which represents the number of selected\n",
        "eigenvectors to extract k direction from all p direction. On the basis of k value we can\n",
        "generate the $Feature vector_{p*k}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2iFRlARZAs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_components(k, V):\n",
        "  # choosing n-components, k\n",
        "  # V is eigenVector\n",
        "  # return k prominent feature i.e our feature vector\n",
        "  return V[:, :k]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI621rGYIo1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "86d59a7f-846d-4ac6-970f-78f0ad20695d"
      },
      "source": [
        "# testing if above method works fine\n",
        "feature_vec = n_components(20, V)\n",
        "print(feature_vec)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.01619146 -0.14205076 -0.04834456 ... -0.0503302  -0.0312666\n",
            "  -0.04161144]\n",
            " [ 0.01466334  0.05644305  0.07213997 ...  0.01304149 -0.04017849\n",
            "   0.02979382]\n",
            " [ 0.02594551  0.08169512 -0.07573807 ...  0.03671764  0.04792784\n",
            "   0.09203496]\n",
            " ...\n",
            " [-0.06892213  0.04050185  0.00732537 ... -0.05274348  0.00949189\n",
            "   0.08832965]\n",
            " [-0.06000398  0.05717431 -0.06674366 ... -0.03730906 -0.04283503\n",
            "   0.06741606]\n",
            " [-0.07397747  0.06151273 -0.02102284 ... -0.07906485 -0.06857713\n",
            "  -0.02775076]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZarYJDZ11utH",
        "colab_type": "text"
      },
      "source": [
        "###3.8 Generating Eigenfaces:\n",
        "For generating the eigenfaces project the each mean aligned face to the generated feature vector\n",
        "**$(eigenfaces)_{k*mn}$ = $(featureVector)^{T}_{k*p}$ * $(dev)^{T}_{p*mn}$ **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqMrUFpgbUAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# projecting each mean aligned face and storing of shape k*mn\n",
        "def gen_eigenface(feature_vec, dev):\n",
        "  # feature_vec: Feature Vector generated using n-components\n",
        "  # dev: Deviation matrix\n",
        "  # Return: EigenFace\n",
        "  return np.dot(feature_vec.T, dev.T)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4KzaBiSJc06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3c975cb-dda5-412a-d64f-2ca1f1554352"
      },
      "source": [
        "# testing if above method works fine\n",
        "eigen_faces = gen_eigenface(feature_vec, dev) \n",
        "eigen_faces.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 10304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_ofCp3G9nAG",
        "colab_type": "text"
      },
      "source": [
        "###3.9 Generating Projection of Each Train Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPIDAQSQbfXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_projection(eigen_faces, dev):\n",
        "  # eigen_faces: Eigen Face \n",
        "  # dev: Deviation matrix\n",
        "  # Return: projection of dataset\n",
        "  return np.dot(eigen_faces, dev)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6het-099tRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "749b76ca-6591-476c-dd31-0e11fa7fcb98"
      },
      "source": [
        "projection_train = gen_projection(eigen_faces, dev) # shape k*p\n",
        "projection_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 320)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btoELNGf2_oj",
        "colab_type": "text"
      },
      "source": [
        "##4. Steps for Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0P5YW6q6YyE",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Visualize the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LMrppW_3Eic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "90f6e215-c513-4c94-ff09-889c74c78caa"
      },
      "source": [
        "print(X_test)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 41.  96.  84. ...  36.  58. 104.]\n",
            " [ 42.  94.  96. ...  36.  48. 100.]\n",
            " [ 47.  98. 101. ...  38.  47. 101.]\n",
            " ...\n",
            " [141. 131.  36. ... 210.  31.  89.]\n",
            " [156. 136.  57. ... 205.  43.  79.]\n",
            " [149. 152.  55. ... 144.  41.  77.]]\n",
            "(10304, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F37KVXaW6mMs",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 DEviation of test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phsSvCnxHbnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de42364e-4190-4cfe-e867-2a9bc68ef1ff"
      },
      "source": [
        "dev_test = X_test - mean # shape mn*p\n",
        "print(dev_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OntbtE3u6tGi",
        "colab_type": "text"
      },
      "source": [
        "###4.3 Project data of test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRvchdvxHs4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f39167b0-3f94-4f4a-ecf7-69cc877ad6ca"
      },
      "source": [
        "projection = gen_projection(eigen_faces, dev_test) # project each data of test dataset, shape=k*mn\n",
        "print(projection.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-zjmU877-Pq",
        "colab_type": "text"
      },
      "source": [
        "###4.4 Eucledian Distance Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV3OTX9p4YPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean(a, b):\n",
        "  return np.sqrt(np.sum(np.power((a-b), 2)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eNT4lQv8Efp",
        "colab_type": "text"
      },
      "source": [
        "###4.5 Check if Above implementation is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z14mhk577GHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "27be4d58-f98f-41c4-ae28-c4a5ab4c17fd"
      },
      "source": [
        "a = np.array([1, 2])\n",
        "b = np.array([1, 2])\n",
        "print(a);print(b)\n",
        "euclidean(a, b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2]\n",
            "[1 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01j_DsV48acu",
        "colab_type": "text"
      },
      "source": [
        "###4.6 Method for calculating closest match"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ2CcXHy3XFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(d):\n",
        "  # d: projection of testing images\n",
        "  minDist = np.finfo('float').max # initialize with max value\n",
        "  minClass = -1 # default closest match initialized\n",
        "  \n",
        "  for i in range(projection_train.shape[1]):\n",
        "    dist = euclidean(projection_train[:, i], d)\n",
        "    if dist < minDist:\n",
        "      minDist = dist\n",
        "      minClass = y_train[i]\n",
        "  return minClass"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmBw8F208_FK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55bd7f92-a958-43b7-f9c3-edd011c2d6d8"
      },
      "source": [
        "correctlyLabeled = 0\n",
        "for i in range(projection.shape[1]):\n",
        "  predicted = predict(projection[:, i])\n",
        "  if(predicted == y_test[i]):\n",
        "    correctlyLabeled += 1\n",
        "  print(\"predicted: \", predicted, \"correct: \", y_test[i])\n",
        "accuracy = correctlyLabeled/projection.shape[1]\n",
        "accuracy"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted:  [14] correct:  [14]\n",
            "predicted:  [31] correct:  [31]\n",
            "predicted:  [35] correct:  [35]\n",
            "predicted:  [20] correct:  [20]\n",
            "predicted:  [25] correct:  [25]\n",
            "predicted:  [7] correct:  [7]\n",
            "predicted:  [16] correct:  [16]\n",
            "predicted:  [27] correct:  [27]\n",
            "predicted:  [15] correct:  [15]\n",
            "predicted:  [22] correct:  [22]\n",
            "predicted:  [35] correct:  [4]\n",
            "predicted:  [14] correct:  [14]\n",
            "predicted:  [12] correct:  [12]\n",
            "predicted:  [40] correct:  [35]\n",
            "predicted:  [2] correct:  [2]\n",
            "predicted:  [6] correct:  [6]\n",
            "predicted:  [30] correct:  [30]\n",
            "predicted:  [15] correct:  [15]\n",
            "predicted:  [21] correct:  [21]\n",
            "predicted:  [20] correct:  [20]\n",
            "predicted:  [18] correct:  [18]\n",
            "predicted:  [27] correct:  [27]\n",
            "predicted:  [13] correct:  [13]\n",
            "predicted:  [15] correct:  [35]\n",
            "predicted:  [18] correct:  [18]\n",
            "predicted:  [2] correct:  [32]\n",
            "predicted:  [8] correct:  [8]\n",
            "predicted:  [2] correct:  [2]\n",
            "predicted:  [29] correct:  [29]\n",
            "predicted:  [11] correct:  [11]\n",
            "predicted:  [18] correct:  [18]\n",
            "predicted:  [31] correct:  [31]\n",
            "predicted:  [34] correct:  [34]\n",
            "predicted:  [23] correct:  [23]\n",
            "predicted:  [7] correct:  [7]\n",
            "predicted:  [8] correct:  [8]\n",
            "predicted:  [10] correct:  [10]\n",
            "predicted:  [18] correct:  [18]\n",
            "predicted:  [18] correct:  [18]\n",
            "predicted:  [40] correct:  [40]\n",
            "predicted:  [11] correct:  [11]\n",
            "predicted:  [33] correct:  [33]\n",
            "predicted:  [1] correct:  [1]\n",
            "predicted:  [1] correct:  [1]\n",
            "predicted:  [30] correct:  [30]\n",
            "predicted:  [6] correct:  [6]\n",
            "predicted:  [38] correct:  [38]\n",
            "predicted:  [26] correct:  [26]\n",
            "predicted:  [16] correct:  [16]\n",
            "predicted:  [24] correct:  [24]\n",
            "predicted:  [25] correct:  [25]\n",
            "predicted:  [15] correct:  [15]\n",
            "predicted:  [30] correct:  [30]\n",
            "predicted:  [13] correct:  [18]\n",
            "predicted:  [29] correct:  [29]\n",
            "predicted:  [32] correct:  [32]\n",
            "predicted:  [6] correct:  [6]\n",
            "predicted:  [2] correct:  [2]\n",
            "predicted:  [3] correct:  [3]\n",
            "predicted:  [5] correct:  [5]\n",
            "predicted:  [8] correct:  [8]\n",
            "predicted:  [28] correct:  [28]\n",
            "predicted:  [1] correct:  [1]\n",
            "predicted:  [36] correct:  [36]\n",
            "predicted:  [20] correct:  [20]\n",
            "predicted:  [38] correct:  [38]\n",
            "predicted:  [15] correct:  [15]\n",
            "predicted:  [16] correct:  [1]\n",
            "predicted:  [16] correct:  [16]\n",
            "predicted:  [32] correct:  [32]\n",
            "predicted:  [1] correct:  [1]\n",
            "predicted:  [27] correct:  [27]\n",
            "predicted:  [7] correct:  [7]\n",
            "predicted:  [3] correct:  [3]\n",
            "predicted:  [11] correct:  [11]\n",
            "predicted:  [2] correct:  [2]\n",
            "predicted:  [37] correct:  [37]\n",
            "predicted:  [31] correct:  [31]\n",
            "predicted:  [37] correct:  [37]\n",
            "predicted:  [33] correct:  [33]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLF1xQ1ebxtI",
        "colab_type": "text"
      },
      "source": [
        "##5. Check for Different K Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVG5h4hNb3JZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de7861fa-85e6-4a28-9588-b28c8ad04cbd"
      },
      "source": [
        "accuracy = []\n",
        "K = []\n",
        "for i in range(2, 82, 20):\n",
        "  K.append(i)\n",
        "K"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 22, 42, 62]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nq4iynWiY9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b99bfb5-3b75-40af-8d11-349ec5cd5a2e"
      },
      "source": [
        "for k in K:\n",
        "  feature_vec = n_components(k, V)\n",
        "  # print(feature_vec.shape)\n",
        "  eigenFace_train = gen_eigenface(feature_vec, dev)\n",
        "  # print(eigenFace_train.shape)\n",
        "  projection_train = gen_projection(eigenFace_train, dev)\n",
        "  # print(projection_train.shape)\n",
        "  projection_test = gen_projection(eigenFace_train, dev_test)\n",
        "  # print(projection_test.shape)\n",
        "  correctlMatch = 0\n",
        "  for i in range(projection_test.shape[1]):\n",
        "    predicted = predict(projection_test[:, i])\n",
        "    if(predicted == y_test[i]):\n",
        "      correctlMatch += 1\n",
        "  accuracy.append(correctlMatch/projection_test.shape[1])\n",
        "print(accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3, 0.925, 0.925, 0.925]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-yE-5YNlS1H",
        "colab_type": "text"
      },
      "source": [
        "## 6. Plotting Accuracy Vs K Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buhl-WyilYHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0d0bc9c4-2456-4ab0-a328-bb0373ef10f0"
      },
      "source": [
        "plt.plot(K, accuracy)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('accuracy') \n",
        "plt.title('accuracy vs k!')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}