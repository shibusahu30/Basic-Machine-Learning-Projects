{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign6_117CS0259.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZRa2TrCrpAk"
      },
      "source": [
        "# Face Recognition Using Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1XmF4ieryC5"
      },
      "source": [
        "##1. Dataset Upload and Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYtec8pvrz_Z"
      },
      "source": [
        "### 1.1 Dataset Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtmW7SrXrf3l"
      },
      "source": [
        "# import dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dDkVUwjr4sR"
      },
      "source": [
        "### 1.2 Dataset Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnSyIBRTr7xq"
      },
      "source": [
        "!unzip att_faces_ORG.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLoJVWkAr7EA"
      },
      "source": [
        "### 1.3 Verify the Dataset\n",
        "Verify if our datasets are correclty imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD09Se6OsBq9",
        "outputId": "a4c2fc30-2fb6-452c-f799-754c732c55a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# to chack the datasets are correctly uploaded and labeled.\n",
        "import os\n",
        "print(os.listdir(os.getcwd()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', '.ipynb_checkpoints', 'att_faces_ORG.zip', 'att_faces', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGYQhWkusFSb"
      },
      "source": [
        "## 2. Import of All Required Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_9iiTjUsF3V"
      },
      "source": [
        "# import required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4-9inCqsIE2"
      },
      "source": [
        "##3. Steps For Training Dataseet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJxB3mANw1x6"
      },
      "source": [
        "### 3.1 Generating Face Dataset\n",
        "Each face image is represented in the form a matrix having m rows and n columns,\n",
        "where each pixel (x,y) such that xm, and yn shows pixel location of the image as\n",
        "well as the direction.\n",
        "For the simplicity we are assuming each face image as a column vector, if we have p\n",
        "images then the size of the face database will be mn*p.<br>\n",
        "Let’s say face database is denoted as $(Face Db)_{mn*p}$*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsufxFzgsMU1",
        "outputId": "9e650271-8009-49e1-fd9b-2eeeee405a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "Face_db = np.zeros(shape=(400, 112*92)) # image input in p*mn format\n",
        "y = np.zeros(shape=(400, 1), dtype=np.int8) # name of the corresponding image\n",
        "p = 0; # increment operator to store each data\n",
        "for i in range(40):\n",
        "  images = os.listdir('./att_faces/s'+str(i+1)) # retrive every folder of my path\n",
        "  for image in images:\n",
        "    img = cv2.imread('./att_faces/s'+str(i+1)+\"/\"+image, cv2.IMREAD_GRAYSCALE) # read the input image\n",
        "    img = np.array(img, dtype=np.float64)\n",
        "    Face_db[p, :] = img.flatten() # flat the image as mentioned in document\n",
        "    y[p] = i+1 # label for the input data image\n",
        "    p += 1 \n",
        "print(Face_db)\n",
        "# print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 34.  34.  33. ...  37.  40.  33.]\n",
            " [ 60.  60.  62. ...  32.  34.  34.]\n",
            " [ 48.  49.  45. ...  47.  46.  46.]\n",
            " ...\n",
            " [119. 120. 120. ...  89.  94.  85.]\n",
            " [123. 121. 126. ...  40.  35.  42.]\n",
            " [128. 125. 125. ...  85.  90.  84.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNIQgY9nSKaM",
        "outputId": "f023ae33-4abe-4934-ae28-5c02b6e627b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# OneHotEncode the y samples\n",
        "enc = OneHotEncoder()\n",
        "y = enc.fit_transform(y).toarray()\n",
        "y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC27uq9lw78l"
      },
      "source": [
        "###3.2 Perform Split of Data for Training and Testing Purpose\n",
        "split the 80% of data for training and remaining for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQHQ7xBAw5BB",
        "outputId": "95bb806c-03c3-4f17-8534-eeb54d166e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Face_db, y, train_size=0.6, random_state=0) # spliting by 60%\n",
        "\n",
        "print(X_train.shape)\n",
        "y_train.shape;\n",
        "X_test.shape;\n",
        "y_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 10304)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDUZxqNHxE4J",
        "outputId": "0c804b03-ef85-44aa-9a79-a217d6040701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train = X_train.T # to convert data to required format i.e mn*p\n",
        "X_test = X_test.T\n",
        "y_train=  y_train.T \n",
        "y_test = y_test.T \n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304, 160)\n",
            "(40, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3UHmgx7xC6c"
      },
      "source": [
        "###3.3 Calculate Mean\n",
        "Calculate the mean of each observation<br>\n",
        "Here mean vector will have the dimension of $(M)_{mn*1}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q287l1exLd4",
        "outputId": "99783b4e-79c6-48bb-fd19-2cf78052d38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean = np.mean(X_train, axis=1)\n",
        "mean = mean.reshape(mean.shape[0], 1) # convert pre ccalculated shape of (mn,) to (mn,1)\n",
        "print(mean.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycIUpAdfxQfL"
      },
      "source": [
        "###3.4 Calculate Deviation Matrix\n",
        "Subtract mean face from each face image, let’s say this mean zero face data as dev."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95NtfQYxQ9u",
        "outputId": "215bab4a-d6d8-4a9a-e835-85dc268b2be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "dev = X_train-mean\n",
        "print(dev)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 13.78333333 -43.21666667  31.78333333 ...  12.78333333  38.78333333\n",
            "   33.78333333]\n",
            " [ 12.5875     -39.4125      33.5875     ...  17.5875      39.5875\n",
            "   31.5875    ]\n",
            " [ 11.19583333 -36.80416667  31.19583333 ...  15.19583333  38.19583333\n",
            "   33.19583333]\n",
            " ...\n",
            " [-26.7375      53.2625       6.2625     ... -34.7375      11.2625\n",
            "    7.2625    ]\n",
            " [-23.66666667  55.33333333   2.33333333 ... -38.66666667   9.33333333\n",
            "    4.33333333]\n",
            " [-23.55833333  49.44166667   4.44166667 ... -38.55833333  13.44166667\n",
            "   10.44166667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notBv-IKxVuP"
      },
      "source": [
        "###3.5 Calculate Co-Variance of the Mean aligned faces \n",
        "Hence here will get covariance matrix of p * p dimension, which is easy to compute and process, the\n",
        "idea behind computing the surrogate covariance suggested by turk and peterland that,\n",
        "these are only the valid direction where we will get maximum variances, and rest of the\n",
        "directions are insignificant to us. Menas these are direction where we will get the\n",
        "eigenvalues and for rest we will get eigenvalues equal to zero.<br>So, take two column matrix and do vector dot prodect to get a scalar and store that in cov matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQKWG3rKxTYD",
        "outputId": "8ab9fe7e-29fb-4bbc-e4ef-7585ea9358b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cov = np.zeros(shape=(320, 320))\n",
        "# for i in range(320):\n",
        "#   for j in range(320):\n",
        "#     cov[i, j] = np.dot(dev[:, i], dev[:, j])\n",
        "# print(cov)\n",
        "cov = np.dot(dev.T, dev) # calculating covariance matrix by above method\n",
        "                        # without using any explicit for loops\n",
        "                        # shape=p*p\n",
        "print(cov.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 240)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXXett7PxaeS"
      },
      "source": [
        "###3.6 Eigenvalue and Eigenvector Decomposition\n",
        "Determine eigenvalue and eigenvector and  select the best direction from p directions, for this sort the eigenvalues in the\n",
        "descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeE7xXKZxbAv",
        "outputId": "7d179292-0f09-4ba8-8b53-da09b060ac76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "lambd, V = np.linalg.eig(cov) # lambd is eigenValue and V is eigenVector\n",
        "idx = np.argsort(lambd)[::-1] # get the indices in descending order according to data\n",
        "lambd = lambd[idx] # sort the value\n",
        "V = V[:, idx] # sort the vector\n",
        "V"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.11387637,  0.03251089, -0.05384041, ..., -0.03594474,\n",
              "         0.0190055 ,  0.06454972],\n",
              "       [-0.07040714,  0.12979555, -0.03369453, ..., -0.00905014,\n",
              "        -0.02242568,  0.06454972],\n",
              "       [-0.02023225, -0.06010655,  0.01932551, ..., -0.00473831,\n",
              "        -0.00059041,  0.06454972],\n",
              "       ...,\n",
              "       [-0.05523633, -0.0683319 ,  0.00106851, ..., -0.00527197,\n",
              "         0.00815422,  0.06454972],\n",
              "       [-0.05721954, -0.07732658, -0.07407796, ..., -0.00470899,\n",
              "        -0.05796219,  0.06454972],\n",
              "       [-0.09227545, -0.06221839, -0.03941263, ...,  0.00225416,\n",
              "        -0.0160272 ,  0.06454972]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWlC_UQ0xe9N"
      },
      "source": [
        "###3.7 Selection of Prominent Features\n",
        "decide a k value, which represents the number of selected\n",
        "eigenvectors to extract k direction from all p direction. On the basis of k value we can\n",
        "generate the $Feature vector_{p*k}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoOrcN8Zxfdd"
      },
      "source": [
        "def n_components(k, V):\n",
        "  # choosing n-components, k\n",
        "  # V is eigenVector\n",
        "  # return k prominent feature i.e our feature vector\n",
        "  return V[:, :k]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Sw8PHJxh4Z",
        "outputId": "e829b297-3116-44c3-8b36-6f4c18a39602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "components = 20\n",
        "feature_vec = n_components(components, V)\n",
        "print(feature_vec)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.11387637  0.03251089 -0.05384041 ...  0.00961343  0.00536039\n",
            "   0.03266572]\n",
            " [-0.07040714  0.12979555 -0.03369453 ... -0.01593011 -0.11272594\n",
            "  -0.02001582]\n",
            " [-0.02023225 -0.06010655  0.01932551 ... -0.05474237 -0.14227077\n",
            "  -0.08819568]\n",
            " ...\n",
            " [-0.05523633 -0.0683319   0.00106851 ... -0.08996113 -0.05833638\n",
            "   0.19310081]\n",
            " [-0.05721954 -0.07732658 -0.07407796 ...  0.06885465 -0.02587326\n",
            "  -0.0355455 ]\n",
            " [-0.09227545 -0.06221839 -0.03941263 ... -0.0217031   0.05432152\n",
            "   0.04413111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDemP6o5yF1w"
      },
      "source": [
        "###3.8 Generating Eigenfaces:\n",
        "For generating the eigenfaces project the each mean aligned face to the generated feature vector\n",
        "**$(eigenfaces)_{k*mn}$ = $(featureVector)^{T}_{k*p}$ * $(dev)^{T}_{p*mn}$ **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kHY9zhHFFma"
      },
      "source": [
        "# projecting each mean aligned face and storing of shape k*mn\n",
        "def gen_eigenface(feature_vec, dev):\n",
        "  # feature_vec: Feature Vector generated using n-components\n",
        "  # dev: Deviation matrix\n",
        "  # Return: EigenFace\n",
        "  return np.dot(feature_vec.T, dev.T)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0kTTxVFFFi1",
        "outputId": "0ede3523-6021-4512-faff-df8e88610e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "eigen_faces = gen_eigenface(feature_vec, dev) \n",
        "eigen_faces.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 10304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOuULNJfFKtf"
      },
      "source": [
        "###3.9 Generating Projection of Each Train Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-qkFqXBFW_-"
      },
      "source": [
        "def gen_projection(eigen_faces, dev):\n",
        "  # eigen_faces: Eigen Face \n",
        "  # dev: Deviation matrix\n",
        "  # Return: projection of dataset\n",
        "  return np.dot(eigen_faces, dev)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVUhj8YGFY95",
        "outputId": "7ca9b481-1932-41a9-e027-e942786dae87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "projection_train = gen_projection(eigen_faces, dev) # shape k*p\n",
        "projection_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DzxKGpHFbeH"
      },
      "source": [
        "###3.10 Define Number of Units for each Layer \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUsWw_xkGBQj"
      },
      "source": [
        "n_x = components # size of the input layer, 20\n",
        "n_h = 1024 # size of the hidden layer\n",
        "n_y = 40 # size of the output layer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uizCpX6Gmbl"
      },
      "source": [
        "# Initialization of parameters \n",
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    n_x -- size of the input layer\n",
        "    n_h -- size of the hidden layer\n",
        "    n_y -- size of the output layer\n",
        "    \n",
        "    Returns:\n",
        "    params -- python dictionary containing your parameters:\n",
        "                    W1 -- weight matrix of shape (n_h, n_x)\n",
        "                    b1 -- bias vector of shape (n_h, 1)\n",
        "                    W2 -- weight matrix of shape (n_y, n_h)\n",
        "                    b2 -- bias vector of shape (n_y, 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
        "    b1 = np.zeros(shape=(n_h, 1))\n",
        "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
        "    b2 = np.zeros(shape=(n_y, 1))\n",
        "    \n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2aCj9fHJW2f"
      },
      "source": [
        "###3.11 Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yf127YEMtNp"
      },
      "source": [
        "# sigmoid\n",
        "def sigmoid(y):\n",
        "  x = y.copy()\n",
        "  return 1/(1+np.exp(-x))\n",
        "# ReLu\n",
        "def relu(y, thresold=0.1):\n",
        "  x = y.copy()\n",
        "  x[x < thresold] = 0\n",
        "  return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKNBad9HJMub"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    X -- input data of size (n_x, m)\n",
        "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
        "    \n",
        "    Returns:\n",
        "    A2 -- The sigmoid output of the second activation\n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    \n",
        "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    \n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2}\n",
        "    \n",
        "    return A2, cache"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bPTt79QOulZ"
      },
      "source": [
        "def compute_cost(A2, Y, parameters):\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy cost given in equation (13)\n",
        "    \n",
        "    Arguments:\n",
        "    A2 -- The sigmoid output of the second activation, of shape (40, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (40, number of examples)\n",
        "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
        "    \n",
        "    Returns:\n",
        "    cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1] # number of example\n",
        "    \n",
        "    # Retrieve W1 and W2 from parameters\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    \n",
        "    # Compute the cross-entropy cost\n",
        "    logprobs = Y * np.log(A2)\n",
        "    cost = - np.sum(logprobs) / m\n",
        "    \n",
        "    cost = np.squeeze(cost)     # makes sure cost is the dimension we expect. \n",
        "                                # E.g., turns [[17]] into 17 \n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69P2xJwJRPET"
      },
      "source": [
        "def backward_propagation(parameters, cache, X, Y):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation using the instructions above.\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing our parameters \n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
        "    X -- input data of shape (20, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (40, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- python dictionary containing your gradients with respect to different parameters\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "        \n",
        "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    \n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
        "    dZ2= A2 - Y\n",
        "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
        "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
        "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEwWsQwGRZbq"
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate=1.2):\n",
        "    \"\"\"\n",
        "    Updates parameters using the gradient descent update rule given above\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients \n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    \n",
        "    # Retrieve each gradient from the dictionary \"grads\"\n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    \n",
        "    # Update rule for each parameter\n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT6A9WkffAdB"
      },
      "source": [
        "def nn_model(X, Y, n_h, num_iterations):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- dataset of shape (20, number of examples)\n",
        "    Y -- labels of shape (40, number of examples)\n",
        "    n_h -- size of the hidden layer\n",
        "    num_iterations -- Number of iterations in gradient descent loop\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    n_x = X.shape[0]\n",
        "    n_y = Y.shape[0]\n",
        "    \n",
        "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "         \n",
        "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
        "        cost = compute_cost(A2, Y, parameters)\n",
        " \n",
        "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
        "        grads = backward_propagation(parameters, cache, X, Y)\n",
        " \n",
        "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
        "        parameters = update_parameters(parameters, grads)\n",
        "        \n",
        "        # Print the cost every 1000 iterations\n",
        "        if i % 1000 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCzVCZgoc1aI",
        "outputId": "0adbb55f-1333-4627-8c2d-afc4cb74474a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameters = nn_model(projection_train, y_train, n_h, 5000)\n",
        "print(parameters)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.708433\n",
            "Cost after iteration 1000: 1.278157\n",
            "Cost after iteration 2000: 0.196221\n",
            "Cost after iteration 3000: 0.441039\n",
            "Cost after iteration 4000: 0.391378\n",
            "{'W1': array([[ 4.89997119e+08,  5.53275611e+07,  7.63680998e+07, ...,\n",
            "         1.51887932e+07, -1.30336750e+07, -1.15107657e+07],\n",
            "       [-4.89848808e+08, -1.08519597e+08,  1.44064860e+08, ...,\n",
            "        -3.54201698e+07,  1.36928668e+07, -2.31805523e+07],\n",
            "       [ 5.32519473e+08,  5.19393401e+07,  8.22500425e+07, ...,\n",
            "         1.77474485e+07, -1.91860506e+07, -1.88326929e+07],\n",
            "       ...,\n",
            "       [ 6.09252554e+08,  2.10705021e+07,  9.05449565e+07, ...,\n",
            "         2.35652182e+07, -2.76176223e+07, -3.82223321e+07],\n",
            "       [-5.37683782e+08, -1.50931161e+08,  1.09535812e+08, ...,\n",
            "        -1.73806278e+07, -5.55914552e+06, -2.72595747e+07],\n",
            "       [-4.03907243e+08, -7.63712243e+07,  1.01574182e+08, ...,\n",
            "        -3.45296520e+07,  1.65761408e+06, -1.60245051e+07]]), 'b1': array([[-1.43390398],\n",
            "       [-2.62761596],\n",
            "       [-1.38780836],\n",
            "       ...,\n",
            "       [-1.49467478],\n",
            "       [-1.21087928],\n",
            "       [-1.27680494]]), 'W2': array([[-0.29991573, -0.09190796, -0.33958011, ..., -0.34229268,\n",
            "        -0.11615996, -0.1085709 ],\n",
            "       [-0.32815265, -0.0347816 , -0.34100579, ..., -0.33030651,\n",
            "        -0.09726001, -0.06566941],\n",
            "       [-0.25112785, -0.35343501, -0.27197   , ..., -0.28004363,\n",
            "         0.01233464, -0.11003031],\n",
            "       ...,\n",
            "       [-0.06708507, -0.34054958, -0.04828124, ..., -0.07106815,\n",
            "        -0.38375228, -0.32431612],\n",
            "       [-0.19724829, -0.42499911, -0.14709119, ..., -0.20661577,\n",
            "        -0.36283876, -0.38867414],\n",
            "       [-0.25051063,  0.46967188, -0.2590095 , ..., -0.23687977,\n",
            "        -0.02078451, -0.04268904]]), 'b2': array([[-0.39113416],\n",
            "       [-0.36412397],\n",
            "       [-0.21819362],\n",
            "       [-0.55366809],\n",
            "       [-0.59310907],\n",
            "       [-0.09560998],\n",
            "       [-0.37559049],\n",
            "       [-0.17406927],\n",
            "       [-0.29357672],\n",
            "       [-0.31237626],\n",
            "       [-0.10234155],\n",
            "       [-0.35642043],\n",
            "       [-0.36750955],\n",
            "       [-0.14079693],\n",
            "       [-0.31533736],\n",
            "       [-0.33582095],\n",
            "       [-0.34539924],\n",
            "       [-0.32897485],\n",
            "       [-0.44088716],\n",
            "       [-0.3886123 ],\n",
            "       [-0.34719726],\n",
            "       [-0.39748403],\n",
            "       [-0.32861764],\n",
            "       [-0.38182568],\n",
            "       [-0.29094817],\n",
            "       [-0.31703891],\n",
            "       [-0.17090639],\n",
            "       [-0.28733518],\n",
            "       [-0.37805192],\n",
            "       [-0.47892492],\n",
            "       [-0.18254068],\n",
            "       [-0.34928731],\n",
            "       [-0.47385394],\n",
            "       [-0.31021801],\n",
            "       [-0.11524444],\n",
            "       [-0.8492778 ],\n",
            "       [-0.29646496],\n",
            "       [-0.40022078],\n",
            "       [-0.66524968],\n",
            "       [-0.25708102]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pd3_ffI_-oY"
      },
      "source": [
        "##4. Steps for Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aKcU7li__s4",
        "outputId": "0a1a6316-6971-43be-be9d-9075bce185ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(X_test)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 50.  37.  86. ... 108. 115. 112.]\n",
            " [ 49.  36.  89. ... 111. 118. 109.]\n",
            " [ 50.  34.  90. ... 110. 117. 112.]\n",
            " ...\n",
            " [159. 160. 124. ...  53.  22.  61.]\n",
            " [111. 207. 116. ...  48.  25.  62.]\n",
            " [117. 210.  83. ...  56.  28.  62.]]\n",
            "(10304, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsKXTOxTAE5C"
      },
      "source": [
        "### 4.2 DEviation of test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6riIORaACD6",
        "outputId": "6bef507f-934c-4ae4-e00d-2498d97d0ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dev_test = X_test - mean # shape mn*p\n",
        "print(dev_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7KvzLjAHEv"
      },
      "source": [
        "###4.3 Project data of test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOSCvDfuAKNv",
        "outputId": "99c52ffa-e648-4efe-816b-4d0d14f3e84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "projection = gen_projection(eigen_faces, dev_test) # project each data of test dataset, shape=k*mn\n",
        "print(projection.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i7dmBOcgRTI"
      },
      "source": [
        "\n",
        "def predict(parameters, X):\n",
        "    \"\"\"\n",
        "    Using the learned parameters, predicts a class for each example in X\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    X -- input data of size (n_x, m)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector of predictions of our model\n",
        "    \"\"\"\n",
        "    \n",
        "    # Computes probabilities using forward propagation\n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    print(A2.shape)\n",
        "    predictions = np.argmax(A2, axis=0)+1\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pJRROST81QH"
      },
      "source": [
        "def predict_model(X, Y, parameters):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  X -- dataset of shape (20, number of examples)\n",
        "  Y -- labels of shape (40, number of examples)\n",
        "  parameters -- python dictionary containing your parameters \n",
        "\n",
        "  Returns\n",
        "  correctyLabled: correctly matched\n",
        "  \"\"\"\n",
        "  correctyLabled = 0\n",
        "  predictions = predict(parameters, X)\n",
        "  print(predictions.shape)\n",
        "  for i in range(X.shape[1]):\n",
        "    print(\"predicted:\", predictions[i], \"correct Label:\", np.argmax(Y[:, i])+1)\n",
        "    if predictions[i] == np.argmax(Y[:, i])+1:\n",
        "      correctyLabled += 1\n",
        "  \n",
        "  return correctyLabled"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1ZZPhROyuU",
        "outputId": "903e0b3b-2bc3-4506-ed0f-39daa27e9a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "correctyLabled = predict_model(projection, y_test, parameters)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 160)\n",
            "(160,)\n",
            "predicted: 14 correct Label: 14\n",
            "predicted: 31 correct Label: 31\n",
            "predicted: 25 correct Label: 35\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 25 correct Label: 25\n",
            "predicted: 36 correct Label: 7\n",
            "predicted: 32 correct Label: 16\n",
            "predicted: 27 correct Label: 27\n",
            "predicted: 15 correct Label: 15\n",
            "predicted: 22 correct Label: 22\n",
            "predicted: 4 correct Label: 4\n",
            "predicted: 14 correct Label: 14\n",
            "predicted: 12 correct Label: 12\n",
            "predicted: 25 correct Label: 35\n",
            "predicted: 19 correct Label: 2\n",
            "predicted: 6 correct Label: 6\n",
            "predicted: 30 correct Label: 30\n",
            "predicted: 15 correct Label: 15\n",
            "predicted: 21 correct Label: 21\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 18 correct Label: 18\n",
            "predicted: 27 correct Label: 27\n",
            "predicted: 13 correct Label: 13\n",
            "predicted: 25 correct Label: 35\n",
            "predicted: 18 correct Label: 18\n",
            "predicted: 32 correct Label: 32\n",
            "predicted: 8 correct Label: 8\n",
            "predicted: 2 correct Label: 2\n",
            "predicted: 29 correct Label: 29\n",
            "predicted: 11 correct Label: 11\n",
            "predicted: 5 correct Label: 18\n",
            "predicted: 31 correct Label: 31\n",
            "predicted: 34 correct Label: 34\n",
            "predicted: 23 correct Label: 23\n",
            "predicted: 7 correct Label: 7\n",
            "predicted: 8 correct Label: 8\n",
            "predicted: 8 correct Label: 10\n",
            "predicted: 18 correct Label: 18\n",
            "predicted: 18 correct Label: 18\n",
            "predicted: 25 correct Label: 40\n",
            "predicted: 11 correct Label: 11\n",
            "predicted: 33 correct Label: 33\n",
            "predicted: 1 correct Label: 1\n",
            "predicted: 5 correct Label: 1\n",
            "predicted: 30 correct Label: 30\n",
            "predicted: 6 correct Label: 6\n",
            "predicted: 23 correct Label: 38\n",
            "predicted: 13 correct Label: 26\n",
            "predicted: 2 correct Label: 16\n",
            "predicted: 24 correct Label: 24\n",
            "predicted: 25 correct Label: 25\n",
            "predicted: 24 correct Label: 15\n",
            "predicted: 30 correct Label: 30\n",
            "predicted: 18 correct Label: 18\n",
            "predicted: 39 correct Label: 29\n",
            "predicted: 32 correct Label: 32\n",
            "predicted: 6 correct Label: 6\n",
            "predicted: 27 correct Label: 2\n",
            "predicted: 26 correct Label: 3\n",
            "predicted: 5 correct Label: 5\n",
            "predicted: 12 correct Label: 8\n",
            "predicted: 28 correct Label: 28\n",
            "predicted: 1 correct Label: 1\n",
            "predicted: 36 correct Label: 36\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 38 correct Label: 38\n",
            "predicted: 15 correct Label: 15\n",
            "predicted: 1 correct Label: 1\n",
            "predicted: 16 correct Label: 16\n",
            "predicted: 32 correct Label: 32\n",
            "predicted: 1 correct Label: 1\n",
            "predicted: 27 correct Label: 27\n",
            "predicted: 7 correct Label: 7\n",
            "predicted: 26 correct Label: 3\n",
            "predicted: 14 correct Label: 11\n",
            "predicted: 2 correct Label: 2\n",
            "predicted: 14 correct Label: 37\n",
            "predicted: 31 correct Label: 31\n",
            "predicted: 37 correct Label: 37\n",
            "predicted: 33 correct Label: 33\n",
            "predicted: 34 correct Label: 34\n",
            "predicted: 10 correct Label: 7\n",
            "predicted: 6 correct Label: 6\n",
            "predicted: 11 correct Label: 11\n",
            "predicted: 15 correct Label: 31\n",
            "predicted: 23 correct Label: 23\n",
            "predicted: 13 correct Label: 13\n",
            "predicted: 9 correct Label: 38\n",
            "predicted: 40 correct Label: 40\n",
            "predicted: 33 correct Label: 33\n",
            "predicted: 39 correct Label: 39\n",
            "predicted: 26 correct Label: 26\n",
            "predicted: 6 correct Label: 6\n",
            "predicted: 1 correct Label: 1\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 15 correct Label: 15\n",
            "predicted: 14 correct Label: 14\n",
            "predicted: 5 correct Label: 40\n",
            "predicted: 27 correct Label: 27\n",
            "predicted: 37 correct Label: 37\n",
            "predicted: 26 correct Label: 26\n",
            "predicted: 7 correct Label: 7\n",
            "predicted: 32 correct Label: 32\n",
            "predicted: 1 correct Label: 16\n",
            "predicted: 20 correct Label: 29\n",
            "predicted: 40 correct Label: 35\n",
            "predicted: 9 correct Label: 9\n",
            "predicted: 13 correct Label: 35\n",
            "predicted: 1 correct Label: 16\n",
            "predicted: 30 correct Label: 30\n",
            "predicted: 10 correct Label: 10\n",
            "predicted: 9 correct Label: 9\n",
            "predicted: 30 correct Label: 30\n",
            "predicted: 40 correct Label: 3\n",
            "predicted: 37 correct Label: 37\n",
            "predicted: 22 correct Label: 22\n",
            "predicted: 28 correct Label: 26\n",
            "predicted: 5 correct Label: 5\n",
            "predicted: 24 correct Label: 24\n",
            "predicted: 39 correct Label: 35\n",
            "predicted: 29 correct Label: 10\n",
            "predicted: 23 correct Label: 23\n",
            "predicted: 24 correct Label: 24\n",
            "predicted: 24 correct Label: 24\n",
            "predicted: 38 correct Label: 38\n",
            "predicted: 15 correct Label: 15\n",
            "predicted: 3 correct Label: 3\n",
            "predicted: 4 correct Label: 26\n",
            "predicted: 19 correct Label: 36\n",
            "predicted: 36 correct Label: 17\n",
            "predicted: 4 correct Label: 16\n",
            "predicted: 35 correct Label: 40\n",
            "predicted: 7 correct Label: 7\n",
            "predicted: 25 correct Label: 25\n",
            "predicted: 39 correct Label: 22\n",
            "predicted: 11 correct Label: 11\n",
            "predicted: 32 correct Label: 32\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 33 correct Label: 33\n",
            "predicted: 15 correct Label: 2\n",
            "predicted: 17 correct Label: 17\n",
            "predicted: 19 correct Label: 19\n",
            "predicted: 4 correct Label: 4\n",
            "predicted: 12 correct Label: 12\n",
            "predicted: 27 correct Label: 27\n",
            "predicted: 11 correct Label: 11\n",
            "predicted: 17 correct Label: 36\n",
            "predicted: 25 correct Label: 25\n",
            "predicted: 24 correct Label: 24\n",
            "predicted: 12 correct Label: 12\n",
            "predicted: 34 correct Label: 34\n",
            "predicted: 13 correct Label: 13\n",
            "predicted: 29 correct Label: 29\n",
            "predicted: 12 correct Label: 12\n",
            "predicted: 39 correct Label: 22\n",
            "predicted: 14 correct Label: 14\n",
            "predicted: 28 correct Label: 28\n",
            "predicted: 13 correct Label: 13\n",
            "predicted: 20 correct Label: 20\n",
            "predicted: 30 correct Label: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-2aLFdYVKp"
      },
      "source": [
        "accuracy = correctyLabled / y_test.shape[1] * 100"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr11wQMpY4Mn",
        "outputId": "ea445571-528b-4e6c-e48c-ab504a65349c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}